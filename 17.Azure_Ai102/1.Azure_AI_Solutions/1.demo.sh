Azure AI solutions

CNN
RNN

Transformer Architecture
Tokenization
Vector Embedding

Tokens and Capacity:

Vectors and Embeddings

Positional ENcoding: is a technique used to preserve order of words when processing natural language.
Attention: Attention figures out each word(or token) in a sequence is important to other words within that sequence by assigning the words weights.
self-attention,
cross-attention,
Multi-Head attention


Supervised Learning(SL): -
This is where the data has been labeled for training. It is considered as task-driven cause we are going to make a pediction get a value back.
So when the labels are known and we want a precise outcome, When we need a specific value returned  -
examples: We will be using Classification, Regression

Unsupervised Learning(USL): -
This is where the data that has not been labeled, The ML model needs to do its own labeling,
This is considered as Data-driven - It recognizes a structure or pattern,
So this  is where the labels are not known and outcome doesnot need to be precise. When we are trying to make sense of data.
Examples: Clustering, Dimensionality Reduction, Association

Reinforcement Learning(RI):
So this is where, There is no data, There is environment and ML model  generates data and makes many attempts to reach a goal.
It is a Decision Driven -
Examples: GameAI, Learning Tasks, Robot Navigation






