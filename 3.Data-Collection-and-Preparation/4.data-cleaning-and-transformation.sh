Once data stored in datalake(data can be in json, pdfs, images etc) - need to do the data analysis

1. Ensure Data Accuracy
2. Remove Redundancies
3. Standardize Formats
4. Handle Mising values
5. Optimize the Data for Analysis

Tools to process and transform data efficiently

1. pandas - A python library for data manipulation and transformation - ideal for small and medium tasks.
2. apache spark - large-scale data processing and transformation.
3. AWS Glue - A serverless service for extracting, transforming and loading(ETL) data.
4. talend - An ETL tool offering drag-and-drop functionality for data integration and transformation.
5. dbt - data build tool , a development framework for transforming data inside datawarehouses.




