RLHF - Reinforcement Learning from Human Feedback

(.venv) bharathkumardasaraju@4.Features$ python3.12 ./8.reinforcement_learning.py
Training reward model with rankings: {'response_1': 1, 'response_2': 2}
Fine-tuning model using reward model: {'trained_model': 'reward_model_v1'}
Final fine-tuned model: {'fine_tuned_model': 'gpt-4-tuned'}
(.venv) bharathkumardasaraju@4.Features$

